{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing 1968 Newspaper text\n",
    "This code was written to analyze data from the Ivy League student newspapers about the Columbia University student protests from April 22 - May 1, 1968. \n",
    "\n",
    "It finds common words overall and sorted by paper name, it runs sentiment analyses, and generally makes the data more manageable.\n",
    "\n",
    "\n",
    "<strong><i>Before starting, run the source code below. Then, run any/all functions.</i></strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glossary:\n",
    "<br>\n",
    "\n",
    "<li><strong>allstories</strong> shows a dataframe of all stories and their calculated polarities and subjectivities based on TextBlob</li>\n",
    "\n",
    "<li><strong>news_subjectivity</strong> shows mean subjectivity of texts grouped by newspaper</li>\n",
    "\n",
    "<li><strong>news_polarity</strong> shows mean polarity of texts grouped by newspaper</li>\n",
    "\n",
    "<li><strong>news_wordcounts</strong> shows sum of word counts in \"Text\" column by newspaper</li>\n",
    "\n",
    "<li><strong>words_bydate</strong> shows number of words, based on \"Word Count\" column, written each day</li>\n",
    "\n",
    "<li><strong>articles_bydate</strong> shows number of articles, grouped by newspaper, written each day</li>\n",
    "\n",
    "<li><strong>frontpage_count</strong> shows how many of a newspaper's stories appeared on the front page</li>\n",
    "\n",
    "<li><strong>notes</strong> shows notes and number of types of notes</li>\n",
    "\n",
    "<li><strong>article_numbers</strong> shows the number of articles from each newspaper</li>\n",
    "\n",
    "<li><strong>authors</strong> shows the names, newspapers, and article frequency of writers</li>\n",
    "\n",
    "<li><strong>common_words()</strong> shows the most common words among all stories</li>\n",
    "\n",
    "<li><strong>least_common_words()</strong> shows the least common words among all stories</li>\n",
    "\n",
    "<li><strong>common_words_in(\"schoolname\")</strong> find most common words from one school's newspaper</li>\n",
    "\n",
    "<li><strong>top_distinct_words()</strong> shows words in each newspaper's top 50 most frequent words which don't overlap with the top 50 words of any other newspaper</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import nltk\n",
    "from textblob import TextBlob\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "import csv\n",
    "import unicodedata\n",
    "import argparse\n",
    "from collections import Counter\n",
    "import string\n",
    "\n",
    "#Read CSV with pandas\n",
    "allstories = pd.read_csv('article-data.csv', encoding='latin1')\n",
    "\n",
    "#Create list of basic polarity and subjectivity measures using TextBlob\n",
    "story_sentiments = []\n",
    "\n",
    "#Iterate through each row to determine polarity and subjectivity\n",
    "#of content in\"Text\" column\n",
    "for row in allstories['Text']:\n",
    "    blob = TextBlob(row)\n",
    "    polarity = blob.sentiment.polarity\n",
    "    subjectivity = blob.sentiment.subjectivity\n",
    "    story_sentiments.append([row,polarity, subjectivity])\n",
    "    \n",
    "#Create dataframe from list\n",
    "sentiments = DataFrame.from_records(story_sentiments)\n",
    "sentiments.columns = ['Text', 'Polarity', 'Subjectivity']\n",
    "\n",
    "#Join data back to information in original dataset\n",
    "allstories = pd.merge(allstories, sentiments, how='right', on=\"Text\")\n",
    "\n",
    "#Drop any duplicates\n",
    "allstories = allstories.drop_duplicates()\n",
    "\n",
    "#news_subjectivity shows mean subjectivity of texts grouped by newspaper\n",
    "news_subjectivity = allstories.groupby(\"Newspaper\")[\"Subjectivity\"].mean()\n",
    "\n",
    "#news_polarity shows mean polarity of texts grouped by newspaper\n",
    "news_polarity = allstories.groupby(\"Newspaper\")[\"Polarity\"].mean()\n",
    "\n",
    "#news_wordcounts shows sum of word counts in \"Text\" column by newspaper\n",
    "news_wordcounts = allstories.groupby(\"Newspaper\")[\"Word Count\"].sum()\n",
    "\n",
    "#words_bydate shows number of words, based on \"Word Count\" column, written each day\n",
    "words_bydate = allstories.groupby(\"Date\")[\"Word Count\"].sum()\n",
    "\n",
    "#articles_bydate shows number of articles, grouped by newspaper, written each day\n",
    "articles_bydate = allstories.groupby([\"Newspaper\", \"Date\"]).size()\n",
    "\n",
    "#frontpage_count shows how many of a newspaper's stories appeared on the front page\n",
    "frontpage_count = allstories.groupby([\"Newspaper\",\"Front page YN\"]).size()\n",
    "\n",
    "#notes shows notes and number of types of notes\n",
    "notes = allstories.groupby([\"Notes\"]).size()\n",
    "\n",
    "#article_numbers shows the number of articles from each newspaper\n",
    "article_numbers = allstories.groupby(\"Newspaper\").size()\n",
    "\n",
    "#authors shows the names, newspapers, and article frequency of writers\n",
    "authors = allstories.groupby([\"Author\",\"Newspaper\"]).size()\n",
    "\n",
    "#common_words() shows the most common words among all stories\n",
    "#Code modified from user MaxU (StackOverflow)\n",
    "\n",
    "def common_words():\n",
    "\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    # RegEx for stopwords\n",
    "    RE_stopwords = r'\\b(?:{})\\b'.format('|'.join(stopwords))\n",
    "    # replace '|'-->' ' \n",
    "    #make all text lowercase\n",
    "    #drop stopwords and punctuation\n",
    "    words = (allstories.Text\n",
    "           .str.lower()\n",
    "           .replace([r'\\|', RE_stopwords], [' ', ''], regex=True)\n",
    "           .str.replace('[^\\w\\s]','')\n",
    "           .str.cat(sep=' ')\n",
    "           .split()\n",
    "    )\n",
    "    \n",
    "    top = 50\n",
    "\n",
    "    # generate DF out of Counter\n",
    "    common_words = pd.DataFrame(Counter(words).most_common(top),\n",
    "                    columns=['Word', 'Frequency'])\n",
    "    return common_words\n",
    "\n",
    "#least_common_words() shows the least common words among all stories\n",
    "def least_common_words():\n",
    "\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    # RegEx for stopwords\n",
    "    RE_stopwords = r'\\b(?:{})\\b'.format('|'.join(stopwords))\n",
    "    # replace '|'-->' ' \n",
    "    #make all text lowercase\n",
    "    #drop stopwords and punctuation\n",
    "    words = (allstories.Text\n",
    "           .str.lower()\n",
    "           .replace([r'\\|', RE_stopwords], [' ', ''], regex=True)\n",
    "           .str.replace('[^\\w\\s]','')\n",
    "           .str.cat(sep=' ')\n",
    "           .split()\n",
    "    )\n",
    "            \n",
    "    # generate DF out of Counter (bottom 100 words)\n",
    "    least_common_words = pd.DataFrame(Counter(words).most_common()[-100:],\n",
    "                    columns=['Word', 'Frequency'])\n",
    "    return least_common_words\n",
    "\n",
    "#common_words_in(\"schoolname\") find most common words from one school's newspaper\n",
    "def common_words_in(schoolname):\n",
    "    from collections import Counter\n",
    "    import pandas as pd\n",
    "    import nltk\n",
    "    import string\n",
    "    \n",
    "    allstories.fillna(value=0, inplace=True)\n",
    "\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    # RegEx for stopwords\n",
    "    RE_stopwords = r'\\b(?:{})\\b'.format('|'.join(stopwords))\n",
    "    # replace '|'-->' ' and drop all stopwords\n",
    "    words = (allstories.loc[allstories['Newspaper'].str.contains(str(schoolname), na=False), 'Text']\n",
    "           .str.lower()\n",
    "           .replace([r'\\|', RE_stopwords], [' ', ''], regex=True)\n",
    "           .str.replace('[^\\w\\s]','')\n",
    "           .str.cat(sep=' ')\n",
    "           .split()\n",
    "    )\n",
    "    top = 50\n",
    "\n",
    "    # generate DF out of Counter\n",
    "    common_in = pd.DataFrame(Counter(words).most_common(top),\n",
    "                    columns=['Word', 'Frequency'])\n",
    "    return common_in\n",
    "\n",
    "#top_distinct_words() shows words in each newspaper's top 50 most frequent words which don't overlap\n",
    "#with the top 50 words of any other newspaper\n",
    "def top_distinct_words():\n",
    "    Harvard_words = common_words_in(\"Harvard\")\n",
    "    Harvard_words['School']='Harvard'\n",
    "\n",
    "    Princeton_words = common_words_in(\"Princeton\")\n",
    "    Princeton_words['School']='Princeton'\n",
    "\n",
    "    Cornell_words = common_words_in(\"Cornell\")\n",
    "    Cornell_words['School']='Cornell'\n",
    "\n",
    "    Pennsylvanian_words = common_words_in(\"Pennsylvanian\")\n",
    "    Pennsylvanian_words['School']='Penn'\n",
    "\n",
    "    Brown_words = common_words_in(\"Brown\")\n",
    "    Brown_words['School']='Brown'\n",
    "\n",
    "    Yale_words = common_words_in(\"Yale\")\n",
    "    Yale_words['School']='Yale'\n",
    "    \n",
    "    #combine all word frequencies\n",
    "    all_word_freq = pd.concat([Harvard_words, Princeton_words, Cornell_words, Pennsylvanian_words, Brown_words, Yale_words])\n",
    "    \n",
    "    #drop duplicate words from most common\n",
    "    no_duplicate_words = all_word_freq.drop_duplicates(subset=['Word'], keep=False)\n",
    "    \n",
    "    #sort by school\n",
    "    no_duplicate_words = no_duplicate_words.sort_values(by=\"School\")\n",
    "    \n",
    "    return no_duplicate_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
